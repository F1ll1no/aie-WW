# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Использовались все 3 датасета: S07-hw-dataset-01.csv, S07-hw-dataset-02.csv, S07-hw-dataset-03.csv

### 1.1 Dataset 1

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12001 строк, 8 признаков (f01-f08)
- Признаки: все числовые (float)
- Пропуски: нет
- "Подлости": разные масштабы признаков (от -100 до +100), разреженные облака, требует масштабирования

### 1.2 Dataset 2

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8001 строк, 3 признака (x1, x2, z_noise)
- Признаки: все числовые (float)
- Пропуски: нет
- "Подлости": много шума в третьем признаке, разная плотность кластеров, DBSCAN находит точки выбросов

### 1.3 Dataset 3

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15001 строк, 4 признака (x1, x2, f_corr, f_noise)
- Признаки: все числовые (float)
- Пропуски: нет
- "Подлости": коррелированные признаки, шумовая компонента, разные масштабы, потребовал 3 кластера

## 2. Protocol

Протокол:

- Препроцессинг: SimpleImputer(strategy='mean') для заполнения пропусков, StandardScaler для масштабирования, PCA(n_components=2) для визуализации
- Поиск гиперпараметров:
  - KMeans: перебор k от 2 до 10, random_state=42, n_init=10
  - DBSCAN: eps в диапазоне [0.2, 0.7] с шагом 0.1, min_samples=3
  - Выбор лучшего метода: по максимуму silhouette score (0-1 шкала, выше лучше)
- Метрики:
  - Silhouette Score (насколько хорошо точка в своем кластере)
  - Davies-Bouldin (среднее расстояние между кластерами, меньше лучше)
  - Calinski-Harabasz (отношение дисперсий между/внутри, больше лучше)
  - Для DBSCAN: точки с меткой -1 исключены из метрик
- Визуализация: PCA 2D для сравнения KMeans и DBSCAN, графики метрик от параметров

## 3. Models

На каждом датасете тестировали KMeans и DBSCAN.

- KMeans: k=2-10, random_state=42, n_init=10, подбирали оптимальное k по silhouette score
- DBSCAN: eps=0.2, 0.3, ..., 0.7; min_samples=3, находили конфигурацию с максимальным silhouette (только non-noise точки)

На Dataset 1: оба метода (KMeans и DBSCAN) дали идентичные результаты (k=2, eps=1.7, silhouette 0.522)
На Dataset 2: DBSCAN превосходит KMeans (silhouette 0.346 vs 0.307)
На Dataset 3: KMeans выигрывает (silhouette 0.316 vs 0.232)

## 4. Results

### 4.1 Dataset 1

- Лучший метод: KMeans, k=2
- Метрики: Silhouette 0.522, Davies-Bouldin 0.685, Calinski-Harabasz 11787
- DBSCAN дал идентичный результат (eps=1.7, no noise)
- Вывод: данные четко разделены на 2 компактных кластера, масштабирование и KMeans справились хорошо

### 4.2 Dataset 2

- Лучший метод: DBSCAN, eps=0.7, min_samples=3
- Метрики: Silhouette 0.346, Davies-Bouldin 0.551, Calinski-Harabasz 10.4
- KMeans показал хуже: Silhouette 0.307
- Шум: 0.7% точек не назначены кластерам
- Вывод: DBSCAN лучше обработал неравномерную плотность данных и шум в третьем признаке

### 4.3 Dataset 3

- Лучший метод: KMeans, k=3
- Метрики: Silhouette 0.316, Davies-Bouldin 1.158, Calinski-Harabasz 6957
- DBSCAN: Silhouette 0.232 (хуже)
- Шум: 0.3% точек
- Вывод: 3 кластера подойдут лучше, KMeans справляется несмотря на коррелированные признаки

## 5. Analysis

### 5.1 Сравнение алгоритмов

KMeans работает хорошо при компактных, сферических кластерах (Dataset 1, Dataset 3). Ломается при неравномерной плотности (Dataset 2 выбрал меньше кластеров из-за расстояний до центроидов).

DBSCAN находит произвольные формы, эффективен когда кластеры разной плотности (Dataset 2). Недостаток: требует ручной настройки eps/min_samples и может дать много шума.

Самый сильный фактор: масштабирование данных. Без StandardScaler результаты были бы намного хуже из-за разных диапазонов признаков (f01 до 100, f03 до 0.002).

### 5.2 Устойчивость (5 запусков KMeans Dataset 1)

5 запусков с разными random_state (42, 123, 456, 789, 999) дали идентичные silhouette score (0.5216).
ARI между парами запусков: все 1.0 (идеальное совпадение разбиения).
Вывод: решение полностью устойчиво, k=2 найден правильно независимо от инициализации.

### 5.3 Интерпретация

Dataset 1: два кластера с противоположными значениями f01, f02 (первый со средними f01~-10, второй ~15). Разделение чистое по 2D PCA проекции.

Dataset 2: DBSCAN нашел два основных кластера с плотностями в (x1,x2) пространстве, выбросы в третьем признаке отклассифицированы как шум.

Dataset 3: три кластера различаются по (x1,x2) координатам, f_corr почти линейно коррелирует с этим, f_noise не влияет на разбиение.

## 6. Conclusion

1. Масштабирование критично: StandardScaler решил многие проблемы, без него результаты были бы случайными.
2. Выбор метода зависит от данных: KMeans быстр для компактных кластеров, DBSCAN спасает при неоднородной плотности.
3. Silhouette score надежнее других метрик: Davies-Bouldin и Calinski-Harabasz дают противоречивые сигналы для DBSCAN с шумом.
4. Устойчивость нужно проверять: на простых данных (Dataset 1) KMeans дает идентичное разбиение при разных seed, но для сложных датасетов это не гарантировано.
5. Визуализация (PCA 2D) критична: график показал, где один метод явно лучше.
6. Пропуски/шум: DBSCAN учел выбросы в Dataset 2, KMeans их усредняет.